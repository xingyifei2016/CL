{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "11e0b4b7-cad6-49c3-affb-7b78b9f169e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from collections import OrderedDict\n",
    "import subprocess\n",
    "import torch\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from pdb import set_trace as st\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ad561bb6-764c-4563-bbf1-ed573ef23c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tasks(num_tasks=10, path=\"/root/yifei/CL_mod/src/dataset/tiny-imagenet-200/tiny-imagenet-200\", seed=0):\n",
    "    # This function creates the corresponding tasks dictionary which maps class_name: task_id\n",
    "     \n",
    "    # Get the file path that stores the class names\n",
    "    file_path = os.path.join(root_path, \"wnids.txt\")\n",
    "    \n",
    "    # Get the class names as a list\n",
    "    lines = [line.rstrip('\\n') for line in open(file_path)]\n",
    "    \n",
    "    # Make sure the tasks are correctly assigned\n",
    "    nb_classes_task = len(lines) // num_tasks\n",
    "    print(\"Split \"+str(len(lines))+\" classes into \"+ str(num_tasks)+\" tasks with \"+str(nb_classes_task)+\" classes per task\")\n",
    "    assert len(lines) % num_tasks == 0, \"total \"+str(len(lines))+\" classes must be divisible by nb classes per task\"\n",
    "    \n",
    "    # Create a dictionary to return in this format: task_number -> class_name\n",
    "    out_dict = {}\n",
    "    for i in range(num_tasks):\n",
    "        out_dict[i] = lines[i*num_tasks:(i+1)*num_tasks]\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "79f45164-82b8-46d4-8cc5-e7023abab90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 200 classes into 10 tasks with 20 classes per task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ['n02124075',\n",
       "  'n04067472',\n",
       "  'n04540053',\n",
       "  'n04099969',\n",
       "  'n07749582',\n",
       "  'n01641577',\n",
       "  'n02802426',\n",
       "  'n09246464',\n",
       "  'n07920052',\n",
       "  'n03970156'],\n",
       " 1: ['n03891332',\n",
       "  'n02106662',\n",
       "  'n03201208',\n",
       "  'n02279972',\n",
       "  'n02132136',\n",
       "  'n04146614',\n",
       "  'n07873807',\n",
       "  'n02364673',\n",
       "  'n04507155',\n",
       "  'n03854065'],\n",
       " 2: ['n03838899',\n",
       "  'n03733131',\n",
       "  'n01443537',\n",
       "  'n07875152',\n",
       "  'n03544143',\n",
       "  'n09428293',\n",
       "  'n03085013',\n",
       "  'n02437312',\n",
       "  'n07614500',\n",
       "  'n03804744'],\n",
       " 3: ['n04265275',\n",
       "  'n02963159',\n",
       "  'n02486410',\n",
       "  'n01944390',\n",
       "  'n09256479',\n",
       "  'n02058221',\n",
       "  'n04275548',\n",
       "  'n02321529',\n",
       "  'n02769748',\n",
       "  'n02099712'],\n",
       " 4: ['n07695742',\n",
       "  'n02056570',\n",
       "  'n02281406',\n",
       "  'n01774750',\n",
       "  'n02509815',\n",
       "  'n03983396',\n",
       "  'n07753592',\n",
       "  'n04254777',\n",
       "  'n02233338',\n",
       "  'n04008634'],\n",
       " 5: ['n02823428',\n",
       "  'n02236044',\n",
       "  'n03393912',\n",
       "  'n07583066',\n",
       "  'n04074963',\n",
       "  'n01629819',\n",
       "  'n09332890',\n",
       "  'n02481823',\n",
       "  'n03902125',\n",
       "  'n03404251'],\n",
       " 6: ['n09193705',\n",
       "  'n03637318',\n",
       "  'n04456115',\n",
       "  'n02666196',\n",
       "  'n03796401',\n",
       "  'n02795169',\n",
       "  'n02123045',\n",
       "  'n01855672',\n",
       "  'n01882714',\n",
       "  'n02917067'],\n",
       " 7: ['n02988304',\n",
       "  'n04398044',\n",
       "  'n02843684',\n",
       "  'n02423022',\n",
       "  'n02669723',\n",
       "  'n04465501',\n",
       "  'n02165456',\n",
       "  'n03770439',\n",
       "  'n02099601',\n",
       "  'n04486054'],\n",
       " 8: ['n02950826',\n",
       "  'n03814639',\n",
       "  'n04259630',\n",
       "  'n03424325',\n",
       "  'n02948072',\n",
       "  'n03179701',\n",
       "  'n03400231',\n",
       "  'n02206856',\n",
       "  'n03160309',\n",
       "  'n01984695'],\n",
       " 9: ['n03977966',\n",
       "  'n03584254',\n",
       "  'n04023962',\n",
       "  'n02814860',\n",
       "  'n01910747',\n",
       "  'n04596742',\n",
       "  'n03992509',\n",
       "  'n04133789',\n",
       "  'n03937543',\n",
       "  'n02927161']}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2bc07814-c993-4fd6-8ef0-63baf1486217",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tinyImageNet(torchvision.datasets.ImageFolder):\n",
    "    # Class that inherits from imagefolder for dataloading purposes\n",
    "    # Applies basic transforms and accepts a subset of classes for training/testing\n",
    "    # Modifies the find_classes function from torch's Dataset class\n",
    "    # Remember in defying paper, train is split 80:20 to train/val; val is for testing\n",
    "    def __init__(self, root=\"/root/yifei/CL_mod/src/dataset/tiny-imagenet-200/tiny-imagenet-200/train\", \n",
    "                 transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),]), \n",
    "                 target_transform=None, subset=None):\n",
    "        # Subset stores a dictionary of class names to its label\n",
    "        self.subset = subset\n",
    "        super().__init__(root=root, transform=transform, target_transform=target_transform)\n",
    "        self.all_classes = torchvision.datasets.folder.find_classes(root)\n",
    "        \n",
    "    def find_classes(self, path):\n",
    "        if self.subset:\n",
    "        # If using a subset of all classes, then only use those classes\n",
    "            return self.subset.keys(), self.subset \n",
    "        else:\n",
    "        # Else, use torch's generalized class function\n",
    "            return torchvision.datasets.folder.find_classes(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d87fbee1-44a1-479f-ad14-188dac19bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tasks(num_tasks=10, path=\"/root/yifei/CL_mod/src/dataset/tiny-imagenet-200/tiny-imagenet-200\"):\n",
    "    # Splitting into n classes creates a n-length array, where each item in the array consists of\n",
    "    # a dictionary that maps class_labels to class_id (ie 0)\n",
    "     \n",
    "    # Get the file path that stores the class names\n",
    "    file_path = os.path.join(root_path, \"wnids.txt\")\n",
    "    \n",
    "    # Get the class names as a list\n",
    "    lines = [line.rstrip('\\n') for line in open(file_path)]\n",
    "    \n",
    "    # Make sure the tasks are correctly assigned\n",
    "    nb_classes_task = len(lines) // num_tasks\n",
    "    print(\"Split \"+str(len(lines))+\" classes into \"+ str(num_tasks)+\" tasks with \"+str(nb_classes_task)+\" classes per task\")\n",
    "    assert len(lines) % num_tasks == 0, \"total \"+str(len(lines))+\" classes must be divisible by nb classes per task\"\n",
    "    \n",
    "    # Create a dictionary to return in this format: task_number -> class_name\n",
    "    outputs = []\n",
    "    current_id = 0\n",
    "    for i in range(num_tasks):\n",
    "        class_lbl = lines[i*num_tasks:(i+1)*num_tasks]  \n",
    "        task_dict = {} \n",
    "        for j in range(i*num_tasks, (i+1)*num_tasks):\n",
    "            task_dict[lines[j]] = current_id\n",
    "            current_id += 1\n",
    "        outputs.append(task_dict)\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "649313bc-667f-498c-b46a-44a7dd83bf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 200 classes into 10 tasks with 20 classes per task\n"
     ]
    }
   ],
   "source": [
    "f = create_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "778ed1bd-496a-4403-bd84-ea2ca4bb3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = tinyImageNet(subset=f[1])\n",
    "train_loader = torch.utils.data.DataLoader(e, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cb48d16b-bc1b-45d8-9ffb-dc5291d3d793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({11: 500,\n",
       "         14: 500,\n",
       "         13: 500,\n",
       "         17: 500,\n",
       "         12: 500,\n",
       "         19: 500,\n",
       "         10: 500,\n",
       "         15: 500,\n",
       "         18: 500,\n",
       "         16: 500})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(e.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d0d52-100b-4fc9-9a23-ed68db77eda3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
